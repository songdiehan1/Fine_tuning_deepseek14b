# ğŸš€ DeepSeek-14B Fine-Tuning Project
This project aims to fine-tune DeepSeek-R1-Distill-Qwen-14B using Zhihu and Xiaohongshu datasets separately. The fine-tuning is conducted using the LoRA method with the Unsloth framework, optimized for Colab + A100 with BF16 support. 

## ğŸ“ Project Structure
```bash
DeepSeek-Finetune/
â”‚â”€â”€ datasets/                        # Dataset folder (JSON data + preprocessing scripts)
â”‚   â”œâ”€â”€ raw/                         
â”‚   â”‚   â”œâ”€â”€ zhihu_data_without_clean.json         
â”‚   â”‚   â”œâ”€â”€ xhs_data_without_clean.json            
â”‚   â”œâ”€â”€ data/                         
â”‚   â”‚   â”œâ”€â”€ zhihu_data.json          
â”‚   â”‚   â”œâ”€â”€ xhs_data.json            
â”‚   â”œâ”€â”€ preprocess_zhihu.py          
â”‚   â”œâ”€â”€ preprocess_xhs.py    
â”‚â”€â”€ models/                                         
â”‚   â”œâ”€â”€zhihu_colab_demo.ipynb            
â”‚   â”œâ”€â”€xhs_colab_demo.ipynb
â”‚â”€â”€ checkpoints/                       
â”‚   â”œâ”€â”€zhihu_checkpoints            
â”‚   â”œâ”€â”€xhs_checkpoints
â”‚â”€â”€ wandb/                       
â”‚   â”œâ”€â”€zhihu_train_loss.png           
â”‚   â”œâ”€â”€xhs_train_loss.png                   
â”‚â”€â”€ requirements.txt                 
â”‚â”€â”€ README.md                        
```

ğŸ“š Setup & Installation
### 1ï¸âƒ£ Install dependencies
Run the following command to install required libraries:
```bash
pip install -r requirements.txt
```
Or manually install:
```
pip install unsloth transformers datasets huggingface_hub wandb
```
### 2ï¸âƒ£Get Weights & Biases key
```bash
import wandb
wb_token = "xxx"
wandb.login(key=wb_token)
run = wandb.init(
    project='fine_tune_deepseek',
    job_type="training",
    anonymous="allow"
)
```
### 3ï¸âƒ£Get Hugging Face key
```bash
from huggingface_hub import login
hf_token = "xxx"
login(hf_token)
```
## ğŸ“š Dataset Information
The dataset used for fine-tuning is available on Hugging Face:  

[![Hugging Face Dataset](https://img.shields.io/badge/HuggingFace-Dataset-yellow)](https://huggingface.co/datasets/Congliu/Chinese-DeepSeek-R1-Distill-data-110k)

## ğŸ›  Performance testing is currently in progress.
**Results and benchmarks will be shared soon!**

## ğŸ”— References
* [DeepSeek on Hugging Face](https://huggingface.co/deepseek-ai)
* [LoRA for Efficient Fine-Tuning](https://arxiv.org/abs/2106.09685)
* [Unsloth Library](https://github.com/unslothai/unsloth)

**ğŸ”¥ Ready to fine-tune DeepSeek? Letâ€™s go! ğŸš€**
